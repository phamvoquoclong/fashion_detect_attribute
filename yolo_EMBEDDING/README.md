# ğŸ§  YOLO Embedding for Attribute Recognition

This folder contains experiments and training code for **fashion attribute recognition** based on **YOLO embeddings**.

Instead of training a separate heavy vision backbone, this approach **reuses a pretrained YOLOv11 detector as a frozen feature extractor**, and learns a lightweight multi-label head on top of object-level crops.

The goal of this module is to **demonstrate feasibility and system integration**, rather than pushing for state-of-the-art attribute accuracy.

---

## ğŸ¯ Objective

- Predict **multiple attributes per object** (multi-label classification)
- Use **cropped object images** as input
- Reuse **YOLOv11 internal feature maps** as embeddings
- Train only a **small fully-connected head**
- Keep the pipeline lightweight and practical

This design aligns with the project requirement:
> *â€œAttribute recognition is required, but accuracy is not the primary KPI.â€*

---

## ğŸ“¦ Dataset

### Dataset Link

ğŸ‘‰ **Fashion Cropped Dataset (Attribute Training)**  
https://www.kaggle.com/datasets/ngusine/fashion-cropped

This dataset was generated by:
- Running object detection
- Cropping detected objects
- **Filtering out crops without attribute annotations**

---

### Dataset Statistics

| Split | Number of Images |
|-----:|-----------------:|
| Train | **206,409** |
| Val   | **5,259** |

Each image corresponds to **one object crop**, with an associated list of attribute IDs.

---

### âš ï¸ Class Filtering Note

Some object categories **do not contain attribute annotations** in Fashionpedia and were therefore removed during dataset preparation.

Examples (after filtering):
sock: 0 / 2582 (0.0%)
shoe: 0 / 46374 (0.0%)
glasses: 0 / 4855 (0.0%)
belt: 0 / 6851 (0.0%)
watch: 0 / 3389 (0.0%)

This filtering ensures:
- Clean supervision signal
- No ambiguous or empty labels
- Stable multi-label training

---

## ğŸ§  Model Design

### ğŸ”¹ Backbone: YOLOv11 (Frozen)

- A **YOLOv11 detector**, pretrained for fashion object detection, is reused
- Feature maps are extracted from a **late layer before the detection head**
- The YOLO backbone is **fully frozen** during attribute training

**Embedding dimension:** `512`

This avoids:
- Training a second backbone
- Duplicating computation
- Overfitting on attribute labels

---

### ğŸ”¹ Attribute Head

A lightweight **fully-connected network** is trained on top of YOLO embeddings.

```text
YOLO Embedding (512)
        â†“
Fully Connected
        â†“
Fully Connected
        â†“
Attribute Scores (N attributes)
```

## ğŸ“¤ Output Representation

### ğŸ”¹ Multi-label Prediction

Each detected object can have **multiple attributes**, for example:

```json
["short length", "plain pattern", "single breasted"]
```

### ğŸ”§ Output & Training Design Choices

#### Therefore:

- **Sigmoid activation** is used at the output layer  
- **Binary Cross-Entropy (BCE)** loss is applied during training  
- **Softmax is NOT used**, because attributes are **not mutually exclusive**

---

### â“ Why Sigmoid Instead of Softmax?

| Reason | Explanation |
|------|------------|
| **Multi-label task** | One object can have multiple attributes |
| **Independent probabilities** | Each attribute is predicted independently |
| **Dataset structure** | Fashionpedia provides attributes as lists, not single labels |

---

## ğŸ§ª Training Strategy

- **Backbone**: Frozen YOLOv11  
- **Trainable parameters**: Attribute head only  
- **Loss function**: Binary Cross-Entropy  
- **Optimizer**: Adam  
- **Batch size**: Tuned for stability and speed  
- **Evaluation**: Validation loss monitoring  

Training code is provided in:

```text
fashion-cropped-train.ipynb
```

This notebook includes:

- Data loading  
- YOLO embedding extraction  
- Training & validation loops  
- Best-checkpoint saving  

---

## ğŸ’¡ Inspiration & References

This approach is inspired by **top solutions from the Fashionpedia Challenge (CVPR 2020)**, where attribute recognition is formulated as a **multi-label classification problem over detected objects**.

<img width="2397" height="1512" alt="image" src="https://github.com/user-attachments/assets/7b66dfd7-3553-4b1f-88dc-f2a75e1ef460" />


ğŸ“ **Reference:**
- Fashionpedia Challenge 2020 (Kaggle / CVPR)

Winning approaches typically:

- Decouple **object detection** and **attribute reasoning**
- Use **object-level representations** for attribute prediction

However, instead of training a full custom architecture, this project:

- Reuses **YOLO embeddings**
- Reduces overall training complexity
- Focuses on **system-level integration** rather than peak benchmark accuracy

---

## ğŸš§ Limitations

- Attribute accuracy is **not fully optimized**
- No class-specific attribute heads
- No attention mechanism between attributes  

These are acceptable trade-offs given the project goal:

> **Demonstrate a working, extensible attribute recognition pipeline**

---

## âœ… Summary

This module demonstrates that:

- YOLO embeddings are sufficient for attribute reasoning  
- Multi-label attribute prediction can be trained efficiently  
- The pipeline integrates cleanly with detection and demo systems  
